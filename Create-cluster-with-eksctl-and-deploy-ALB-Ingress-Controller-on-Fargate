# EKS ã¨ã¯

AWS ãŒæä¾›ã—ã¦ã„ã‚‹ãƒãƒãƒ¼ã‚¸ãƒ‰å‹ã® Kubernetes ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚
ã“ã®è¨˜äº‹ã§ã¯ã€å…·ä½“çš„ãªæ§‹æˆã‚’ã‚‚ã¨ã«å®Ÿéš›ã«è§¦ã£ã¦ã¿ã‚‹ã“ã¨ã§ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æ¨™ã¨ã—ã¾ã™ã€‚

EKS ã§ä½œæˆã—ãŸã€€Kubernetesã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ã¯åˆ¥ã«
Docker Desktop ãªã©ã§ä½œæˆã—ãŸ Kubernetesã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è§¦ã‚Šã¤ã¤é€²ã‚ã‚‹ã¨åˆ†ã‹ã‚Šã‚„ã™ã‹ã£ãŸã§ã™ã€‚
(ä½•ã‹ Error ãŒã‚ã£ãŸéš›ã«ã‚‚åˆ‡ã‚Šåˆ†ã‘ã‚„åŸå› ç©¶æ˜ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™)
ğŸ‘†ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®åˆ‡ã‚Šæ›¿ãˆã¯ Docker ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å¯èƒ½ãªã®ã§ Docker Desktop ãŒãŠè–¦ã‚ã§ã™ã€‚

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ä½œæˆæ–¹æ³•

AWS EKS (Elastic Kubernetes Service) ã‚’åˆ©ç”¨ã—ã¦ Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã¾ã§è¡Œã„ã¾ã™ã€‚

é–‹å§‹æ–¹æ³•ã¯2é€šã‚Šã‚ã‚Šã¾ã™ã€‚

- EKS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆ
- eksctl ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆ

ä»Šå›ã¯ VPC ã‚„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ãªã©å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã‚‚ä½µã›ã¦è‡ªå‹•è¨­å®šã§ãã‚‹ `eksctl` ã‚’ç”¨ã„ã¦ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’è¡Œã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
å‚è€ƒ: [Getting Started with eksctl - Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html)

ã¾ãŸã€å†…éƒ¨ã§ç¨¼åƒã—ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒŠ (EC2) ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚‹ Fargate ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã€ã“ã¡ã‚‰ã®å…¬å¼ Blog ã‚‚å‚è€ƒã«ã—ã¾ã™ã€‚
å‚è€ƒ: [Amazon EKS on AWS Fargate Now Generally Available | AWS News Blog](https://aws.amazon.com/jp/blogs/aws/amazon-eks-on-aws-fargate-now-generally-available/)

# ç’°å¢ƒ

Kubernetes 1.14
AWS EKS
AWS Fargate
Docker for mac
Mojavi 10.14.6

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦

âš `Kubernetes 1.14ç³»`ã¯è„†å¼±æ€§ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™ï¼
(ã‚ãŸã—ã®æ¤œè¨¼æ™‚ã¯æœªå ±å‘Šã§ã—ãŸ)
åˆ¥ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®æ¤œè¨¼ã‚’ã‚ªã‚¹ã‚¹ãƒ¡ã—ã¾ã™ã€‚
[CVE-2019-11247: API server allows access to custom resources via wrong scope Â· Issue #80983 Â· kubernetes/kubernetes](https://github.com/kubernetes/kubernetes/issues/80983)

**Vulnerable versions:**
- Kubernetes 1.7.x-1.12.x
- Kubernetes 1.13.0-1.13.8
- Kubernetes 1.14.0-1.14.4
- Kubernetes 1.15.0-1.15.1

**Fixed versions:**
- Fixed in v1.13.9
- Fixed in v1.14.5
- Fixed in v1.15.2
- Fixed in master

# å‚ç…§

[Amazon EKS ã§ã® AWS Fargate ã®é–‹å§‹æ–¹æ³• - Amazon EKS](https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/fargate-getting-started.html
)


# EKS ã®ä¸‹æº–å‚™

## AWS CLI ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```console
$ brew install awscli --upgrade --user
```

`hostname doesn't match ` ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ï¼Ÿ
=> ç¢ºèª: Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ 2.7.9 ä»¥ä¸Šã‹ç¢ºèªã‚’

## IAMãƒ¦ãƒ¼ã‚¶ãƒ¼

1. å¿…è¦ã«å¿œã˜ã¦æ¤œè¨¼ç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆ
2. ä½¿ç”¨ã™ã‚‹ IAM ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¦ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’ä½œæˆã™ã‚‹
3. AWS CLI ã« AWS èªè¨¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹

### å¿…è¦ã«å¿œã˜ã¦æ¤œè¨¼ç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆ

IAMãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¨©é™ãŒã†ã¾ãæŒ¯ã‚Œã¦ã„ãªã„ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆã§å¤±æ•—ã—ã¾ã™ã€‚
æ¤œè¨¼æ®µéšã§ã¯ **å°ã•ãæ¤œè¨¼ ï¼† æ¨©é™ã‚’å¤§ãã‚ã«æŒ¯ã‚‹** ã§è©¦ã—ã¦ã¿ã¦ã€å°‘ã—ãšã¤æ¨©é™ã‚’ç‹­ã‚ã¦ã„ãã¨ã€åŠ¹ç‡ã‚ˆãé€²ã‚ã‚‰ã‚Œã‚‹ã®ã§ã‚ªã‚¹ã‚¹ãƒ¡ã§ã™ã€‚

### ä½¿ç”¨ã™ã‚‹ IAM ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¦ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’ä½œæˆã™ã‚‹

IAM ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ç”»é¢ã‹ã‚‰ã€ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚

<img width="1139" alt="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2020-02-26 10.52.16.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/b4feac8d-ab91-0b27-8c29-b357314d35ea.png">

`AWS Access Key ID`ã¨`AWS Secret Access Key`ãŒç™ºè¡Œã•ã‚Œã‚‹ã®ã§ä¿å­˜ã™ã‚‹ã€‚

### AWS CLI ã« AWS èªè¨¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹

`$ aws configure`ã‚’å®Ÿè¡Œã™ã‚‹ã¨
AWS CLI ã«ã‚ˆã£ã¦`ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼`ã€`ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼`ã€`AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³`ã€`å‡ºåŠ›å½¢å¼`ã€ä»¥ä¸Š4ã¤ã®æƒ…å ±ã®å…¥åŠ›ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã‚‰ã¯è‡ªå‹•çš„ã« `default` ã¨ã„ã†åå‰ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šç¾¤ã«ä¿å­˜ã•ã‚Œã‚‹ã€‚(æ—¢ã«è¨­å®šã—ã¦ã‚ã‚‹å ´åˆã¯ä¸Šæ›¸ãã•ã‚Œã‚‹ã®ã§æ³¨æ„ï¼)

- `~/.aws` ä»¥ä¸‹ã® config ã¨ credentials ãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºèªå¯èƒ½ã€‚
- æ‰‹å‹•ä¿®æ­£ã™ã‚‹ãªã©ã—ã¦ã€è¤‡æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã‚‚å¯èƒ½ã€‚
- å‚è€ƒ: [åå‰ä»˜ããƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - AWS Command Line Interface](
https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/cli-configure-profiles.html)

```console
$ aws configure
AWS Access Key ID [None]: ğŸ†”ï¼Šï¼Šï¼Šï¼Šï¼Š
AWS Secret Access Key [None]: ğŸ”‘ï¼Šï¼Šï¼Šï¼Šï¼Š
Default region name [None]: ap-northeast-1
Default output format [None]: json
```

è¤‡æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šãªã©ã®è©³ã—ã„æ–¹æ³•ã¯ä»¥ä¸‹ã®è¨˜äº‹ã«ã¾ã¨ã‚ã¦ã‚ã‚Šã¾ã™ã€‚
[AWS CLIè¨­å®šã®ã‚¢ãƒ¬ã‚³ãƒ¬](https://qiita.com/suwa3/items/ba730274b7228b7a1b71)

## eksctl ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

AWS ãŒã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼çš„ã«ä¿æœ‰ã—ã¦ã„ã‚‹ brew å½¢å¼ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```console
$ brew tap weaveworks/tap
```

eksctl ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```console
$ brew install weaveworks/tap/eksctl
```

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããŸã‹ç¢ºèªã€‚

```console
$ eksctl version
```

## ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚ 

ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã—ãŸã‚‰ç´„15åˆ†å¾…ã¤ã€‚

```console
$ eksctl create cluster --name demo-cluster --region ap-northeast-1 --fargate
```

å†…éƒ¨ã§ Cloud Formation ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚
ã‚³ãƒ¼ãƒ’ãƒ¼ã§ã‚‚é£²ã¿ãªãŒã‚‰å¾…ã¡ã¾ã™â˜•

## ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç¢ºèª

ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã«ã‚ã‚‹ Docker ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/fe01ad53-3475-57f0-aaca-7e41c8ca5060.png)

## ãƒãƒ¼ãƒ‰ä¸€è¦§ã‚’è¡¨ç¤º

ãƒãƒ¼ãƒ‰ä¸€è¦§ã‚’è¡¨ç¤ºã•ã›ãŸã¨ã“ã‚
fargate ãŒå‹•ã„ã¦ã„ã¾ã—ãŸã€‚

```console
$ kubectl get nodes
NAME                                                         STATUS   ROLES    AGE   VERSION
fargate-ip-***-***-***-**.ap-northeast-1.compute.internal    Ready    <none>   9d    v1.14.8-eks
fargate-ip-***-***-***-***.ap-northeast-1.compute.internal   Ready    <none>   9d    v1.14.8-eks
```

kube-system ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚

```console
$ kubectl get po --all-namespaces
NAMESPACE     NAME                      READY   STATUS    RESTARTS   AGE
kube-system   coredns-d784dc748-pkfqv   1/1     Running   0          9d
kube-system   coredns-d784dc748-t9pq5   1/1     Running   0          9d
```

# EKS ç”¨ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ç”¨é€”ã«ã‚ˆã£ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒä½•ç¨®é¡ã‹ã‚ã‚Šã¾ã™ã€‚
ã‚·ãƒ³ã‚°ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¦ã‚‚ã€ãƒãƒ«ãƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦åˆ¥ã€…ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã‚‚ OK ã§ã™ã€‚

- Deployment
- Service
- Ingress
- Secret
- ServiceAccount

ãªã©ãªã©ã€‚ã€‚
ä»Šå›ã¯ deployment.yml ã¨ service.yml ã‚’ä½œæˆã—ã¦æ¤œè¨¼ã‚’è¡Œã„ã¾ã™ã€‚


## ä½œæ¥­å ´æ‰€ã‚’ä½œæˆ

```console
$ mkdir kube
$ cd kube/
```

## å˜ä¸€ã® nginx Deployment ã‚’ä½œæˆ

ä¸‹è¨˜ã®å†…å®¹ã§ deployment.yml ã‚’ä½œæˆ / ç·¨é›†ã—ã¾ã™ã€‚
nginx-deployment.yml ã‚’ä½œæˆ

```console
$ vi nginx-deployment.yml
```

```yml:nginx-deployment.yml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.5
        ports:
        - containerPort: 80
```


```console
$ kubectl apply -f nginx-deployment.yml
deployment.extensions/nginx created
```

Pod ä¸€è¦§ã‚’è¡¨ç¤ºã•ã›ã¾ã™ã€‚

```console
$ kubectl get pod
NAME                    READY   STATUS    RESTARTS   AGE
nginx-954765466-zmj5p   0/1     Pending   0          9s
```

å…¨ãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹ã®ã€Podä¸€è¦§ã‚’è¡¨ç¤ºã•ã›ã¾ã™ã€‚

```console
// kubernets 1.13ã¾ã§
$ kubectl get pods --all-namespaces
// kubernetes 1.14ä»¥é™
$ kubectl get pod -A
```

å…¨ãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹ã®ã€ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ã‚’è¡¨ç¤ºã•ã›ã¾ã™ã€‚

```console
$ kubectl get svc --all-namespaces
NAMESPACE     NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
default       kubernetes   ClusterIP   10.100.0.1    <none>        443/TCP         9d
kube-system   kube-dns     ClusterIP   10.100.0.10   <none>        53/UDP,53/TCP   9d
```

## Service ä½œæˆ

ä»¥ä¸‹ã®å†…å®¹ã§ service.yml ã‚’ã€€ä½œæˆ / ç·¨é›†ã—ã¾ã™ã€‚
nginx-service.yml ã¨ã„ã† yaml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã€‚

```console
$ vi nginx-service.yml
```

```yml:nginx-service.yml
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    app: nginx
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
  externalIPs:
     - 10.100.0.1
```

service ã‚’ä½œæˆã—ã¾ã™ã€‚

```
$ kubectl apply -f nginx-service.yml
service/nginx created
```

è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹ã®ç¢ºèªã€‚

```console
$ kubectl get svc --all-namespaces
NAMESPACE     NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
default       kubernetes   ClusterIP   10.100.0.1      <none>        443/TCP         9d
default       nginx        ClusterIP   10.100.77.190   10.100.0.1    80/TCP          10s
kube-system   kube-dns     ClusterIP   10.100.0.10     <none>        53/UDP,53/TCP   9d
```

## deployment.yml ã§è¨­å®šã—ãŸ Pod ã‚’è‰²ã€…ãªè§’åº¦ã§è¦‹ã¦ã¿ã‚‹

### Podã®è©³ç´°ã‚’è¡¨ç¤º

çµæ§‹ãªæƒ…å ±é‡ã€‚ã€‚

```console
$ kubectl describe pod nginx
```

ğŸ‘†å®Ÿè¡Œã™ã‚‹ã¨
ä¸‹è¨˜ã®ã‚ˆã†ãªè©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```yml
Name:           nginx-954765466-zmj5p
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Fri, 31 Jan 2020 20:33:22 +0900
Labels:         app=nginx
                pod-template-hash=5754944d6c
Annotations:    <none>
Status:         Running
IP:             10.1.0.141
Controlled By:  ReplicaSet/nginx-deployment-5754944d6c
Containers:
  nginx:
    Container ID:   docker://0ae17409e095d3a13c4bca879fc7095f92d0effd221b0053cf024acb809b358d
    Image:          nginx:1.7.9
    Image ID:       docker-pullable://nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sun, 23 Feb 2020 19:30:16 +0900
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-slqvm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-slqvm:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-slqvm
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>

Name:           nginx-deployment-5754944d6c-9d6lf
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Fri, 31 Jan 2020 20:33:22 +0900
Labels:         app=nginx
                pod-template-hash=5754944d6c
Annotations:    <none>
Status:         Running
IP:             10.1.0.140
Controlled By:  ReplicaSet/nginx-deployment-5754944d6c
Containers:
  nginx:
    Container ID:   docker://ac1c96d75b4e32ce7ab8eecd4e0ede68077e55bbf03c1a655d3a870b421d711c
    Image:          nginx:1.7.9
    Image ID:       docker-pullable://nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sun, 23 Feb 2020 19:30:16 +0900
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-slqvm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-slqvm:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-slqvm
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>
```

### Pod ã®ãƒ­ã‚°ã‚’å‚ç…§ã™ã‚‹

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ Pod ã®ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã“ã¨ãŒå‡ºæ¥ã¾ã™ã€‚

```console
$ kubectl logs <pod-name>
```

api-server ã®ãƒ­ã‚°ã‚’è¡¨ç¤ºã•ã›ã¦ã¿ã¾ã—ãŸã€‚

```console
$ kubectl logs kube-apiserver-docker-desktop -n kube-system
Flag --insecure-port has been deprecated, This flag will be removed in a future version.
I0223 10:30:03.769470       1 server.go:560] external host was not specified, using 192.168.65.3
I0223 10:30:03.772335       1 server.go:147] Version: v1.15.5
I0223 10:30:05.417959       1 plugins.go:158] Loaded 10 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,MutatingAdmissionWebhook.
(ã€œç•¥ã€œ)
```

### å¤–ã‹ã‚‰Podã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã¿ã‚‹ (port fowardç·¨)

service.yml ã‚’æ›¸ã‹ãªãã¦ã‚‚
èµ·å‹•ã§ãã¦ã„ã‚‹ã‹ã®ç¢ºèªã§ã‚ã‚Œã°ã€ port foward ã§ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

Pod ã®ä¸€è¦§ã‚’è¡¨ç¤ºã€‚
ã“ã¡ã‚‰ã¯ãƒ¬ãƒ—ãƒªã‚«æ•° 1 ã§èµ·å‹•ã—ã¦ã„ã‚‹ã®ã§ã€ã²ã¨ã¤ã ã‘è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```console
$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-954765466-zmj5p   1/1     Running   0          5h59m
```

port foward ã§ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ç¹‹ã’ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```console
$ kubectl port-forward nginx-954765466-zmj5p 8080:80
Forwarding from 127.0.0.1:8080 -> 80
Forwarding from [::1]:8080 -> 80
Handling connection for 8080
```

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/cf47599c-6f6c-1b2b-7d2b-5a599e51abcb.png)


å•é¡Œãªãè¡¨ç¤ºã§ãã¾ã—ãŸğŸ‘

#### æƒé™¤æ–¹æ³•

```console
$ kubectl get deployment
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   2/2     2            2           26d
```

deployment ã®å‰Šé™¤ã€‚

```console
$ kubectl delete deployment nginx-deployment
deployment.extensions "nginx-deployment" deleted
```

# ç–‘å•:thinking:: `kubectl apply` ã¨ `kubectl create` ã®é•ã„

ã©ã¡ã‚‰ã‚‚ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦æ§‹ç¯‰ã™ã‚‹ã•ã„ã«ä½¿ã†ã‚³ãƒãƒ³ãƒ‰

- `kubectl apply -f  <ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«>` 
- `kubectl create -f <ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«>`

apply ã¯ URL æŒ‡å®šã§ã€ create ã¯ã‚«ãƒ¬ãƒ³ãƒˆã«ã‚ã‚‹ yml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã™ã‚‹ã¨ãã«ä½¿ã£ã¦ã„ã‚‹ã€‚
å…·ä½“çš„ãªé•ã„ã‚’èª¿ã¹ã¦ã¿ã¾ã™ã€‚

[Kubernetes: kubectl apply ã®å‹•ä½œ](https://qiita.com/tkusumi/items/0bf5417c865ef716b221)
>kubectl apply ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆã—ã€å­˜åœ¨ã™ã‚Œã°å·®åˆ†ã‚’åæ˜ ã—ã¦ãã‚Œã‚‹ä¾¿åˆ©ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚(ç•¥)apply ä»¥å¤–ã® create, replace ãªã©ã®ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã¯ã€ç¾åœ¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ…‹ã‚’æ„è­˜ã—ã¦æ“ä½œã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ãªã‚‹ã»ã©ã€œã€œ

ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå­˜åœ¨ã—ãªã„ | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå­˜åœ¨ã™ã‚‹
--- | --- | ---
apply   | :white_check_mark: æ–°è¦ä½œæˆ ( POST ) | :white_check_mark: å·®åˆ†åæ˜  ( PATCH, DELETE )
create  | :white_check_mark: æ–°è¦ä½œæˆ ( POST ) | :warning:  ã‚¨ãƒ©ãƒ¼
replace | :warning: ã‚¨ãƒ©ãƒ¼   | :white_check_mark: ä¸Šæ›¸ã ( PUT )
patch   | :warning: ã‚¨ãƒ©ãƒ¼   | :white_check_mark: å·®åˆ†åæ˜  ( PATCH )
delete  | :warning: ã‚¨ãƒ©ãƒ¼   | :white_check_mark: å‰Šé™¤ ( DELETE )

(ä¸Šè¨˜URLã‹ã‚‰å¼•ç”¨)

## çµè«–â­: kubectl applyãŒå„ªç§€

# docker-desktopğŸ³ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ§‹ç¯‰

ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã«ã‚ã‚‹ Docker ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰ docker-desktop ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

<img width="634" alt="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2020-02-27 18.07.34.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/3b44fa48-6422-cee2-d963-d96db762e40c.png">

```
$ ls
sample-deployment.yml	sample-service.yml
```

## deployment.yml 

```
$ vi sample-deployment.yml 
```

```yml:sample-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-app
  labels:
    app: sample-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sample-app
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - image: aoi1/tofu-sample-app:1.0
        name: sample-app
        ports:
        - containerPort: 3000
          name: sample-app
```

## service.yml 

```console
$ vi sample-service.yml 
```

```yml:sample-service.yml
apiVersion: v1
kind: Service
metadata:
  name: sample-app
spec:
  type: NodePort
  selector:
    app: sample-app
  ports:
    - name: "http-port"
      protocol: "TCP"
      port: 80
      targetPort: 3000
```

â€»`type:NodePort`ã§ã‚¯ãƒ©ã‚¹ã‚¿å¤–ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½

## Service ãŒé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹è¦‹ã¦ã¿ã‚‹

`$ kubectl apply` ã§ä½œæˆã—ã¦ã„ãã¾ã™ã€‚

```console
$ kubectl apply -f sample-deployment.yml
deployment.apps/sample-app created

$ kubectl apply -f sample-service.yml
service/sample-app created
```

Service ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚

```console
$ kubectl get service
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        26d
sample-app   NodePort    10.109.160.47   <none>        80:32763/TCP   73s
```

ãƒ–ãƒ©ã‚¦ã‚¶ã§ Service ã® Port ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã¿ã¾ã™ã€‚

http://127.0.0.1:32763

ã‚ãƒ¼ã„ã€ã§ãã¾ã—ãŸ ğŸ‘

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/6ed3a657-b3ed-3432-dfc9-7378e8b72448.png)


Deployment ã ã‘ã§ã¯ã€ port foward ã—ã¦ã‚ã’ãªã„ã¨ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ç¢ºèªãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
Service ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒå›ºå®šã•ã‚Œã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

[Kubernetesã® Service ã«ã¤ã„ã¦ã¾ã¨ã‚ã¦ã¿ãŸ](https://qiita.com/kouares/items/94a073baed9dffe86ea0)


>**Service ã®å½¹å‰²**
Podã¯Nodeã«æ•£ã‚‰ã°ã£ã¦ã„ã‚‹ãŸã‚ã€ãã‚Œãã‚Œã®Podã¨é€šä¿¡ã—ã‚ˆã†ã¨ã—ãŸã‚‰ã€æ„šç›´ã«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŒ‡å®šã—ã¦é€šä¿¡ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚
ã¾ãŸã€K8sã®ç‰¹æ€§ä¸Šã€Nodeã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¯ä¸€å®šã«ãªã‚Šã¾ã›ã‚“ã€‚
çªç„¶Podã¨é€šä¿¡ã§ããªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
ã¨ã„ã†ã“ã¨ã¯ã€è¤‡æ•°ã®Pod,Nodeã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ„è­˜ã›ãšã«å˜ä¸€ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§é€šä¿¡ã™ã‚‹æ–¹æ³•ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚
ä¸Šè¨˜ã®äº‹è±¡ã«å¯¾ã™ã‚‹è§£æ±ºç­–ã¨ã—ã¦Pod,Nodeã®å­˜åœ¨ã‚’æŠ½è±¡åŒ–ã—ã€Podã¨ã®é€šä¿¡ã«å˜ä¸€ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã™ã‚‹ã®ãŒServiceã®ä¸»ãªå½¹å‰²ã«ãªã‚Šã¾ã™ã€‚

# EKS ç”¨ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰

EKS ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/c772c4f3-f5ec-8ddc-8d32-d0762709ad05.png)

EKS ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ docker-desktop åŒæ§˜ã« yaml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦
ãƒ–ãƒ©ã‚¦ã‚¶ã§ Service ã® Port ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã¿ã¾ã—ãŸãŒã€è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚
ãã¬ã¬

### ãªãœè¡¨ç¤ºã•ã‚Œãªã„ã®ã‹

[Serviceã®å…¬é–‹ (Serviceã®ã‚¿ã‚¤ãƒ—)](https://kubernetes.io/ja/docs/concepts/services-networking/service/#publishing-services-service-types)

>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã„ãã¤ã‹ã®éƒ¨åˆ†ã«ãŠã„ã¦(ä¾‹ãˆã°ã€frontendsãªã©)ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å¤–éƒ¨ã«ã‚ã‚‹IPã‚¢ãƒ‰ãƒ¬ã‚¹ä¸Šã§Serviceã‚’å…¬é–‹ã—ãŸã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ (ã€œç•¥ã€œ)
LoadBalancer: ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€Serviceã‚’å¤–éƒ¨ã«å…¬é–‹ã—ã¾ã™ã€‚

[Amazon EKS ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ Kubernetes Services ã‚’å…¬é–‹ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ ?](https://aws.amazon.com/jp/premiumsupport/knowledge-center/eks-kubernetes-services-cluster/)

>æ³¨æ„ : Amazon EKS ã¯ã€Load Balancer ã‚’é€šã˜ã¦ Amazon Elastic Compute Cloud (Amazon EC2) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒãƒƒãƒ‰ã«å¯¾ã—ã¦ Network Load Balancer ã¨ Classic Load Balancer ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚Amazon EKS ã¯ã€AWS Fargate ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒãƒƒãƒ‰ã® Network Load Balancer ãŠã‚ˆã³ Classic Load Balancer ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚

EC2 ä¸Šã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã«ãŠã„ã¦ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ã‚µãƒãƒ¼ãƒˆã‚ã‚‹ã‘ã‚Œã©
Fargate ã®å ´åˆã¯ãªã„ã‚‰ã—ã„ã§ã™ã€‚

>Fargate ã‚¤ãƒ³ã‚°ãƒ¬ã‚¹ã®å ´åˆã€Amazon EKS ã§ ALB Ingress Controller (æœ€å°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 1.1.4) ã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã™ã€‚

**Fargate ã‚’ä½¿ã†éš›ã«ã¯ã€ALB Ingress Controller ã‚’ä½¿ã„ã¾ã—ã‚‡ã†**
ã¨ã®ã“ã¨ã§ã™ï¼

ã¨ã„ã†ã“ã¨ã§ `LoadBalancer` ã‚’æŒ‡å®šã—ã¦ã€ Fargate ä¸Šã§ Service ã®å…¬é–‹ãŒã§ããªã‹ã£ãŸã¨ã„ã†ã®ã¯ã€ **ã‚€ã—ã‚æœŸå¾…å€¤ã§ã‚ã‚‹** ã¨ã„ã†ã“ã¨ãŒåˆ¤æ˜ã—ãŸã®ã§æ¤œè¨¼ã‚’ç¶šã‘ã¾ã™ã€‚
å¤–éƒ¨ã‹ã‚‰è¡¨ç¤ºã•ã›ã¦ã¿ãŸã„ã®ã§ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã‚ã‚‹ ALB Ingress Controller ã®ä½¿ç”¨ã‚’ã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

# ALB Ingress Controller ã®æ¤œè¨¼

ã“ã“ã‚’å‚è€ƒã«é€²ã‚ã¾ã™ã€‚
[Amazon EKS ã® ALB Ingress Controller](https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/alb-ingress.html)

>AWS ALB Ingress Controller for Kubernetesã¯ã€kubernetes.io/ingress.class: alb æ³¨é‡ˆã‚’ä»˜ã‘ã¦ Ingress ãƒªã‚½ãƒ¼ã‚¹ãŒã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ä½œæˆã•ã‚Œã‚‹ãŸã³ã«ã€Application Load Balancer (ALB) ãŠã‚ˆã³å¿…è¦ãª AWS ã‚µãƒãƒ¼ãƒˆãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã§ã™ã€‚

GitHub ã«ã‚½ãƒ¼ã‚¹ä¸ŠãŒã£ã¦ã„ã¾ã—ãŸã€‚
https://github.com/kubernetes-sigs/aws-alb-ingress-controller

ã‚¬ã‚¤ãƒ‰ã‚³ãƒ¼ãƒŠãƒ¼ã§ã™ã€‚ Route53 ã‚’ä½¿ã†ã¨ãã¯ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚è€ƒã«ã—ã¾ã™ã€‚
[Spec - AWS ALB Ingress Controller](https://kubernetes-sigs.github.io/aws-alb-ingress-controller/guide/ingress/spec/)

ä¸€åº¦ã€å˜ä¸€ Service æ§‹æˆã§ Ingress ã‚’æ¤œè¨¼ã—ã¦ã¿ã¾ã™ã€‚
[Ingress - Kubernetes](https://kubernetes.io/ja/docs/concepts/services-networking/ingress/#%E5%8D%98%E4%B8%80service%E3%81%AEingress
)

```
$ ls
sample-deployment.yml	sample-ingress.yml	sample-service.yml
```

## deployment.yml 

```
$ vi sample-deployment.yml 
```

```yml:sample-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-app
  labels:
    app: sample-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sample-app
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - image: aoi1/tofu-sample-app:1.0
        name: sample-app
        ports:
        - containerPort: 3000
          name: sample-app
```

## service.yml 

```
$ vi sample-service.yml
```

```yml:sample-service.yml
apiVersion: v1
kind: Service
metadata:
  name: sample-app
spec:
  type: NodePort
  selector:
    app: sample-app
  ports:
    - name: "http-port"
      protocol: "TCP"
      port: 80
      targetPort: 3000
```

## ingress.yml

```
$ vi sample-ingress.yml
```

```yml:sample-ingress.yml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: sample-app
  annotations:
    kubernetes.io/ingress.class: alb
spec:
  backend:
    serviceName: sample-app
    servicePort: 80
```

`ingress` ã‚’ä½œæˆã€‚

```console
$ kubectl apply -f sample-ingress.yml
ingress.networking.k8s.io/sample-app created
```

```console
$ kubectl get ingress 
NAME         HOSTS   ADDRESS   PORTS   AGE
sample-app   *                 80      107s
```

## æº–å‚™

### ã‚µãƒ–ãƒãƒƒãƒˆã¨ ALB ã®ç´ä»˜ã‘

ä½¿ç”¨ã™ã‚‹ VPC ã®ã‚µãƒ–ãƒãƒƒãƒˆã«ã‚¿ã‚°ã‚’ä»˜ã‘ã¦ã€ãã®ã‚µãƒ–ãƒãƒƒãƒˆã‚’ä½¿ç”¨ã§ãã‚‹ã“ã¨ã‚’
ALB Ingress Controller ã«ä¼ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

â€» ekctl ã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸå ´åˆã¯ã€ã‚¿ã‚°ãŒã™ã§ã«é©ç”¨ã•ã‚Œã¦ã„ã‚‹ãŸã‚ä¸è¦ã€‚

### IAM OIDC ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆã—ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«é–¢é€£ä»˜ã‘

```console
$ eksctl utils associate-iam-oidc-provider \
    --region ap-northeast-1 \
    --cluster demo-cluster \
    --approve
```

IAM OIDC ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã£ã¦ãªã‚“ã ã‚ã†
- [Kubernetes ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«å¯¾ã™ã‚‹ãã‚ç´°ã‚„ã‹ãª IAM ãƒ­ãƒ¼ãƒ«å‰²ã‚Šå½“ã¦ã®ç´¹ä»‹ | Amazon Web Services ãƒ–ãƒ­ã‚°](https://aws.amazon.com/jp/blogs/news/introducing-fine-grained-iam-roles-service-accounts/)
- [[ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ] EKSã§IAMãƒ­ãƒ¼ãƒ«ã‚’ä½¿ã£ãŸPodå˜ä½ã®ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸï¼ ï½œ Developers.IO](https://dev.classmethod.jp/cloud/aws/eks-supports-iam-roles-for-service-accounts/)

ãªã‚‹ã»ã©ãªã‚‹ã»ã©~

```console
$ eksctl utils associate-iam-oidc-provider --region ap-northeast-1 --cluster demo-cluster --approve
[â„¹]  eksctl version 0.13.0
[â„¹]  using region ap-northeast-1
[â„¹]  will create IAM Open ID Connect provider for cluster "demo-cluster" in "ap-northeast-1"
[âœ”]  created IAM Open ID Connect provider for cluster "demo-cluster" in "ap-northeast-1"
```

IAM ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ç¢ºèªã€‚
ã§ãã¾ã—ãŸğŸ‘

<img width="850" alt="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2020-03-04 14.09.27.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/2acd5b6e-3eb6-01df-199b-799b9055c3a4.png">


## IAM ãƒãƒªã‚·ãƒ¼ã®ä½œæˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»£ã‚ã£ã¦ AWS API ã‚’å‘¼ã³å‡ºã™ã“ã¨ã‚’
ALB Ingress Controller Pod ã«è¨±å¯ã™ã‚‹ãŸã‚ã®
ALBIngressControllerIAMPolicy ã¨ã„ã† IAM ãƒãƒªã‚·ãƒ¼ã‚’ä½œæˆã€‚

```console
$ aws iam create-policy \
    --policy-name ALBIngressControllerIAMPolicy \
    --policy-document https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/iam-policy.json
```

å®Ÿè¡Œã—ã¦ã¿ã¾ã—ãŸã€‚

```console
$ aws iam create-policy --policy-name ALBIngressControllerIAMPolicy --policy-document https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/iam-policy.json
{
    "Policy": {
        "PolicyName": "ALBIngressControllerIAMPolicy", 
        "PermissionsBoundaryUsageCount": 0, 
        "CreateDate": "2020-03-04T05:24:33Z", 
        "AttachmentCount": 0, 
        "IsAttachable": true, 
        "PolicyId": "ANPAWRYCWNNWLBILX6M2P", 
        "DefaultVersionId": "v1", 
        "Path": "/", 
        "Arn": "arn:aws:iam::*********:policy/ALBIngressControllerIAMPolicy", 
        "UpdateDate": "2020-03-04T05:24:33Z"
    }
}
```

- alb-ingress-controller ã¨ã„ã†åå‰ã® Kubernetes ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ kube-system åå‰ç©ºé–“ã«ä½œæˆã€‚
- ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ«ã¨ ALB Ingress Controller ã§ä½¿ç”¨ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½œæˆã€‚

```console
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/rbac-role.yaml
clusterrole.rbac.authorization.k8s.io/alb-ingress-controller created
clusterrolebinding.rbac.authorization.k8s.io/alb-ingress-controller created
serviceaccount/alb-ingress-controller created
```

ALB Ingress Controller ã® IAM ãƒ­ãƒ¼ãƒ«ã‚’ä½œæˆã—
ã“ã®ãƒ­ãƒ¼ãƒ«ã‚’å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½œæˆã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚¢ã‚¿ãƒƒãƒã™ã‚‹ã€‚

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã€ eksctl ã§ä½œæˆã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã®ã¿ä½¿ç”¨ã§ãã‚‹ã€‚

```console
$ eksctl create iamserviceaccount \
    --region ap-northeast-1 \
    --name alb-ingress-controller \
    --namespace kube-system \
    --cluster demo-cluster \
    --attach-policy-arn arn:aws:iam::***********:policy/ALBIngressControllerIAMPolicy \
    --override-existing-serviceaccounts \
    --approve
```

å®Ÿè¡Œã—ãŸã€‚ã‚¢ã‚¿ãƒƒãƒã§ãã¾ã—ãŸã€‚

```console
$ eksctl create iamserviceaccount --region ap-northeast-1 --name alb-ingress-controller --namespace kube-system --cluster demo-cluster --attach-policy-arn arn:aws:iam::***********:policy/ALBIngressControllerIAMPolicy --override-existing-serviceaccounts --approve
[â„¹]  eksctl version 0.13.0
[â„¹]  using region ap-northeast-1
[â„¹]  1 iamserviceaccount (kube-system/alb-ingress-controller) was included (based on the include/exclude rules)
[!]  metadata of serviceaccounts that exist in Kubernetes will be updated, as --override-existing-serviceaccounts was set
[â„¹]  1 task: { 2 sequential sub-tasks: { create IAM role for serviceaccount "kube-system/alb-ingress-controller", create serviceaccount "kube-system/alb-ingress-controller" } }
[â„¹]  building iamserviceaccount stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-alb-ingress-controller"
[â„¹]  deploying stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-alb-ingress-controller"
[â„¹]  serviceaccount "kube-system/alb-ingress-controller" already exists
[â„¹]  updated serviceaccount "kube-system/alb-ingress-controller"

```

## ALB Ingress Controller ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤

```console
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/alb-ingress-controller.yaml
deployment.apps/alb-ingress-controller created
```

ALB Ingress Controller ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ç·¨é›†ã€‚
--ingress-class=alb è¡Œã®å¾Œã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åã®è¡Œã‚’è¿½åŠ ã™ã‚‹ã€‚
Fargate ã§ ALB Ingress Controller ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€ VPC ID ã®è¡Œã¨ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã® AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åã‚‚è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
ä¸€éƒ¨æŠœç²‹

```console
$ kubectl edit deployment.apps/alb-ingress-controller -n kube-system

    spec:
      containers:
      - args:
        - --ingress-class=alb
        - --cluster-name=demo-cluster
        - --aws-vpc-id=vpc-***********
        - --aws-region=ap-northeast-1
```

å…¨éƒ¨

```console
$ kubectl edit deployment.apps/alb-ingress-controller -n kube-system
```

```yml
  selfLink: /apis/apps/v1/namespaces/kube-system/deployments/alb-ingress-controller
  uid: ***********
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: alb-ingress-controller
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: alb-ingress-controller
    spec:
      containers:
      - args:
        - --ingress-class=alb
        - --cluster-name=demo-cluster
        - --aws-vpc-id=vpc-***********
        - --aws-region=ap-northeast-1
        image: docker.io/amazon/aws-alb-ingress-controller:v1.1.4
        imagePullPolicy: IfNotPresent
        name: alb-ingress-controller
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: alb-ingress-controller
      serviceAccountName: alb-ingress-controller
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2020-03-04T07:57:41Z"
    lastUpdateTime: "2020-03-04T07:57:41Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-03-04T07:51:13Z"
    lastUpdateTime: "2020-03-04T07:57:41Z"
    message: ReplicaSet "alb-ingress-controller-***********" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 2
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1
```


ALB Ingress Controller ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚
è‰¯ã•ãã†ã€‚

```console
$ kubectl get pods -n kube-system
NAME                                      READY   STATUS    RESTARTS   AGE
alb-ingress-controller-***********   1/1     Running   0          97s
coredns-d784dc748-fmkzx                   1/1     Running   0          23h
coredns-d784dc748-r28sm                   1/1     Running   0          23h
```

## ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤

ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åå‰ç©ºé–“ã‚’å«ã‚€ Fargate ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚

```console
$ eksctl create fargateprofile --cluster demo-cluster --region ap-northeast-1 --name alb-sample-app --namespace 2048-game
[â„¹]  creating Fargate profile "alb-sample-app" on EKS cluster "demo-cluster"
[â„¹]  created Fargate profile "alb-sample-app" on EKS cluster "demo-cluster"
```

ã§ãã¾ã—ãŸğŸ™Œ

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/4216e328-5687-e675-89e0-a3d84fe4960c.png)


ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦é©ç”¨ã—
- Kubernetes ã®åå‰ç©ºé–“
- Deployment
- Serviceã‚’ä½œæˆ

```console
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/2048/2048-namespace.yaml
namespace/2048-game created

$ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/2048/2048-deployment.yaml
deployment.apps/2048-deployment created

$ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/2048/2048-service.yaml
service/service-2048 created
```

å…¥åŠ›ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```console
$ curl -o 2048-ingress.yaml https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.4/docs/examples/2048/2048-ingress.yaml
```

`2048-ingress.yaml` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã€‚
æ—¢å­˜ã® `alb.ingress.kubernetes.io/scheme: internet-facing` è¡Œã®ä¸‹ã«
è¡Œ `alb.ingress.kubernetes.io/target-type: ip` ã‚’è¿½åŠ ã™ã‚‹ã€‚

```console
$ vi 2048-ingress.yaml
```

```yml:2048-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: "2048-ingress"
  namespace: "2048-game"
  annotations:
    kubernetes.io/ingress.class: alb 
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
  labels:
    app: 2048-ingress
spec:
  rules:
    - http:
        paths:
          - path: /*
            backend:
              serviceName: "service-2048"
              servicePort: 80
```

å…¥åŠ›ã—ãŸãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©ç”¨

```console
$ kubectl apply -f 2048-ingress.yaml
ingress.extensions/2048-ingress created
```

ä½œæˆã«æ•°åˆ†ã‹ã‹ã‚‹ã®ã§ã‚³ãƒ¼ãƒ’ãƒ¼ã‚’é£²ã¿ãªãŒã‚‰å¾…ã¡ã¾ã™ã€‚
Ingress ãƒªã‚½ãƒ¼ã‚¹ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

```console
$ kubectl get ingress/2048-ingress -n 2048-game
NAME           HOSTS   ADDRESS                                                                       PORTS   AGE
2048-ingress   *       cc1babba-2048game-2048ingr-*************.ap-northeast-1.elb.amazonaws.com   80      5m50s
```

æŒ‡å®šã•ã‚ŒãŸ ADDRESS ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã€‚
http://cc1babba-2048game-2048ingr-6fa0-*********.ap-northeast-1.elb.amazonaws.com/

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449552/34aa2468-f131-86ab-8ec0-af095272ff07.png)

ã§ãã¾ã—ãŸğŸ‘

